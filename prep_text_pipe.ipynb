{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from pyaspeller import YandexSpeller, Word\n",
    "from spellchecker import SpellChecker\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "speller = YandexSpeller()\n",
    "russian = SpellChecker(language='ru')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# тестовые данные\n",
    "data = pd.read_csv('data.csv')\n",
    "data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "import importlib\n",
    "importlib.reload(nlp_functions)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'nlp_functions' from '/home/u53r/vscodeprojects/nlp_functions.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "from nlp_functions import nlp_preprocessing\n",
    "from preprocessing_functions.tf_idf_preprocessing import tf_idf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Препроцессинг текста"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "importlib.reload(nlp_functions)\n",
    "nlp_params = dict()\n",
    "\n",
    "## Основные параметры\n",
    "nlp_params['train'] = data # основной датасет\n",
    "nlp_params['oos'] = None  # out-of-sample при наличии (необязательный параметр)\n",
    "nlp_params['oot'] = None  # out-of-time при наличии (необязательный параметр)\n",
    "nlp_params['text_field'] = 'text'  # название столбца с текстом\n",
    "\n",
    "## Простой препроцессинг\n",
    "nlp_params['need_del_dash'] = False  # удаление тире\n",
    "nlp_params['need_lower_case'] = True  # приведение к нижнему регистру\n",
    "nlp_params['need_del_number'] = False  # удаление чисел\n",
    "nlp_params['need_del_in_brackets'] = False  # внутри скобок\n",
    "nlp_params['need_del_eng'] = False  # английские буквы\n",
    "\n",
    "## Поиск опечаток (spellcheker)\n",
    "nlp_params['need_spellchecker'] = True  # запуск поиска опечаток [True, False]\n",
    "# действия над опечатками [delete, replace, nothing(default)] / рекомендуется использовать replace - работает в разы быстрее\n",
    "nlp_params['need_del_spell'] = 'replace'\n",
    "\n",
    "## Лемматизация\n",
    "nlp_params['need_lemma'] = True  # запуск лемматизации [True, False]\n",
    "nlp_params['need_lru_cache'] = True  # использование декоратора для ускорения процесса лемматизации [True, False] (рекомендуется)\n",
    "\n",
    "## Поиск сущностей (NER) | поиск сущностей следует запускать только после лемматизации слов\n",
    "nlp_params['need_ner'] = True  # запуск поиска сущностей [True, False]\n",
    "nlp_params['need_del_number_ner'] = 'nothing'  # действия над числами [delete, replace, nothing(default)]\n",
    "nlp_params['need_del_name'] = 'replace'  # действия над именами (также)\n",
    "nlp_params['need_del_org'] = 'replace'  # действия над названиями организаций (также)\n",
    "nlp_params['need_del_geo'] = 'nothing'  # действия над локациями (также)\n",
    "nlp_params['need_del_months'] = False  # действия над месяцами (True - delete, False - nothing)\n",
    "\n",
    "## Настройки для стопслов\n",
    "nlp_params['need_del_stopwords'] = True  # действия над стопсловами [True, False]\n",
    "nlp_params['new_stopwords'] = []  # новый список стопслов ['word1', 'word2']\n",
    "# режим работы со стопсловами, какие стопслова используются ['default list', 'default list + additional list', 'only additional list']\n",
    "nlp_params['mode_stopwords'] = 'default list'  \n",
    "\n",
    "train, oos, oot = nlp_preprocessing(**nlp_params)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "123231243\n",
      "Trash chars done! - 0:00:00.005594\n",
      "\n",
      "\n",
      "\n",
      "Lemmatization / Spellcheker / NER done! - 0:00:01.847416\n",
      "\n",
      "Delete stop words done! - 0:00:00.005605\n",
      "Preprocessing done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "train.text[6]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Добрый день! Ищем пляжный отдых для матери с ребенком (13), отель не ниже 4, чтобы был пляж и трансфер из аэропорта. Не особо дорого'"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "train.new_prep_text[6]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'добрый день искать пляжный отдых мать ребенок 13 отель ниже 4 пляж трансфер аэропорт особо дорого'"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Векторизация текста с помощью TFiDF"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "tf_idf_params = dict()\n",
    "\n",
    "params = { # Параметры TFidfVectorizer()\n",
    "    'ngram_range': (1, 1) # задаем размер н-грамм\n",
    "}\n",
    "\n",
    "## Основные параметры\n",
    "tf_idf_params['train'] = train # основной датасет\n",
    "tf_idf_params['oos'] = None  # out-of-sample при наличии (необязательный параметр)\n",
    "tf_idf_params['oot'] = None  # out-of-time при наличии (необязательный параметр)\n",
    "tf_idf_params['text_field'] = 'new_prep_text'  # название столбца с текстом\n",
    "tf_idf_params['target_name'] = None  # название поля с таргетом\n",
    "\n",
    "## Параметры TFiDF\n",
    "tf_idf_params['params'] = params\n",
    "\n",
    "train, oos, oot = tf_idf(**tf_idf_params)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "train['R'] = data['R']\n",
    "d = [0]*16\n",
    "d.extend([1]*16)\n",
    "d.append(1)\n",
    "train['R'] = d\n",
    "train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Классификация"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train.drop('R', axis=1), train['R'], train_size=0.6, random_state=5)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train,y_train)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "source": [
    "max_acc = 0\n",
    "from joblib import Parallel, delayed\n",
    "def chk(i, x_train, x_test, y_train, y_test):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train.drop('R', axis=1), train['R'], train_size=0.5, random_state=i)\n",
    "\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(x_train,y_train)\n",
    "    acc = accuracy_score(y_test, nb.predict(x_test))\n",
    "    return acc\n",
    "\n",
    "print(max(Parallel(n_jobs=12)(delayed(chk)(i, x_train, x_test, y_train, y_test) for i in range(100000))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9411764705882353\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "source": [
    "accuracy_score(y_test, nb.predict(x_test))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7058823529411765"
      ]
     },
     "metadata": {},
     "execution_count": 194
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Регрессия"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lm = LogisticRegression()\n",
    "lm.fit(x_train, y_train)\n",
    "accuracy_score(y_test, lm.predict(x_test))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7058823529411765"
      ]
     },
     "metadata": {},
     "execution_count": 193
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a51130aba350de0b703ff9648ee257d60a31a7a49fccfbd89ac13108e97eeb72"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('anaconda3': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}