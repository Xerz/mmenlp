{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from glob import glob\n",
    "\n",
    "\n",
    "def make_translation(source, target):\n",
    "    assert len(source) == len(target)\n",
    "    return {\n",
    "        ord(a): ord(b)\n",
    "        for a, b in zip(source, target)\n",
    "    }\n",
    "\n",
    "\n",
    "DASHES_TRANSLATION = make_translation(\n",
    "    '‑–—−',\n",
    "    '----'\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    text = text.replace('\\xad', '')\n",
    "    text = text.translate(DASHES_TRANSLATION)\n",
    "    return text\n",
    "    \n",
    "texts = []\n",
    "for path in sorted(glob('texts/*.txt')):\n",
    "    with open(path) as file:\n",
    "        text = file.read()\n",
    "        text = preprocess(text)\n",
    "        texts.append(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from random import seed, sample\n",
    "\n",
    "seed(2)\n",
    "for text in sample(texts, 3):\n",
    "    print(text)\n",
    "    print('---' * 10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lines = []\n",
    "for text in texts:\n",
    "\tfor line in text.splitlines():\n",
    "\t\tlines.append(line)\n",
    "\t\t\n",
    "sample(lines, 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import display\n",
    "\n",
    "from ipymarkup import show_span_box_markup as show_markup\n",
    "\n",
    "from yargy import (\n",
    "    Parser,\n",
    "    or_, rule\n",
    ")\n",
    "from yargy.pipelines import morph_pipeline\n",
    "from yargy.predicates import (\n",
    "    eq, in_, dictionary,\n",
    "    type, gram\n",
    ")\n",
    "from yargy.tokenizer import MorphTokenizer\n",
    "from yargy import interpretation as interp\n",
    "from yargy.interpretation import fact, attribute\n",
    "\n",
    "\n",
    "def show_matches(rule, *lines):\n",
    "    parser = Parser(rule)\n",
    "    for line in lines:\n",
    "        matches = parser.findall(line)\n",
    "        matches = sorted(matches, key=lambda _: _.span)\n",
    "        spans = [_.span for _ in matches]\n",
    "        show_markup(line, spans)\n",
    "        if matches:\n",
    "            facts = [_.fact for _ in matches]\n",
    "            if len(facts) == 1:\n",
    "                facts = facts[0]\n",
    "            display(facts)\n",
    "\n",
    "INT = type('INT')\n",
    "NOUN = gram('NOUN')\n",
    "ADJF = gram('ADJF')\n",
    "PRTF = gram('PRTF')\n",
    "GENT = gram('gent')\n",
    "DOT = eq('.')\n",
    "\n",
    "\n",
    "TOKENIZER = MorphTokenizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%run -n -i rules/budget.py\n",
    "\n",
    "parser = Parser(BUDGET)\n",
    "seed(1)\n",
    "for line in sample(lines, 30):\n",
    "    matches = list(parser.findall(line))\n",
    "    spans = [_.span for _ in matches]\n",
    "    show_markup(line, spans)\n",
    "    if matches:\n",
    "        match = matches[0]\n",
    "        display(match.tree.as_dot)\n",
    "        display(match.fact)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%run -n -i rules/children.py\n",
    "\n",
    "parser = Parser(KIDS_NUMBER)\n",
    "seed(1)\n",
    "for line in sample(lines, 70):\n",
    "    matches = list(parser.findall(line))\n",
    "    spans = [_.span for _ in matches]\n",
    "    show_markup(line, spans)\n",
    "    if matches:\n",
    "        match = matches[0]\n",
    "        display(match.tree.as_dot)\n",
    "        display(match.fact)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%run -n -i rules/children.py\n",
    "\n",
    "parser = Parser(KIDS_FOOD)\n",
    "seed(1)\n",
    "for line in sample(lines, 30):\n",
    "    matches = list(parser.findall(line))\n",
    "    spans = [_.span for _ in matches]\n",
    "    show_markup(line, spans)\n",
    "    if matches:\n",
    "        match = matches[0]\n",
    "        display(match.tree.as_dot)\n",
    "        display(match.fact)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%run -n -i rules/misc.py\n",
    "\n",
    "parser = Parser(UAI)\n",
    "seed(1)\n",
    "for line in sample(lines, 30):\n",
    "    matches = list(parser.findall(line))\n",
    "    spans = [_.span for _ in matches]\n",
    "    show_markup(line, spans)\n",
    "    if matches:\n",
    "        match = matches[0]\n",
    "        display(match.tree.as_dot)\n",
    "        display(match.fact)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%run -n -i rules/children.py\n",
    "show_matches(KIDS_NUMBER, 'Нас три семьи. Первая 2 взрослых и двое детей. Вторая двое взрослых и 1 ребенок и третья семья 2 взрослых. Это мы взрослых детей хотим от себя отселить. Нам нужно на море на 2 недели и чтобы мы могли уместиться в 200 тысяч.')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2cf870773758035b938b81f22e6070e2526a88a16b51765671f7a44fc858513"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}